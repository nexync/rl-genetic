{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cc132f9-71f7-4474-8125-af59604c706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52ead826-65f6-4fa8-9089-d2358137f817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n",
      "Discrete(2)\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space)\n",
    "print(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03b7d609-dc09-48b0-8bbc-6b411aaf8d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03880385, -0.03644115, -0.00643382, -0.01485287], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e691ba22-6f1f-480d-994f-82c467d78eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.12889609 -1.145766    0.22302017  1.9903542 ] 1.0 14\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "done = False\n",
    "env.reset()\n",
    "counter = 0\n",
    "while not done:\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    display.display(plt.gcf())    \n",
    "    display.clear_output(wait=True)\n",
    "    action = env.action_space.sample()\n",
    "    pos, rew, done, _ = env.step(action)\n",
    "    counter += 1\n",
    "    if done:\n",
    "        print(pos, rew, counter)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66c6294d-2acf-4d12-8b44-0bed16d3bec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import random\n",
    "import math\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fee97b5f-5c77-4661-9fb3-16b114fb45a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(4, 24)\n",
    "        self.fc2 = nn.Linear(24, 48)\n",
    "        self.fc3 = nn.Linear(48, 2)\n",
    "    def forward(self, x):        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73f1475e-9e79-4f39-9b85-c25c03794798",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNCartPoleSolver:\n",
    "    def __init__(self, n_episodes=2000, n_win_ticks=195, max_env_steps=None, gamma=1.0, epsilon=1.0, epsilon_min=0.01, epsilon_log_decay=0.995, alpha=0.01, alpha_decay=0.01, batch_size=64, monitor=False, quiet=False):\n",
    "        self.memory = deque(maxlen=100000)\n",
    "        self.env = gym.make('CartPole-v0')\n",
    "        if monitor: \n",
    "            self.env = gym.wrappers.Monitor(self.env, '../data/cartpole-1', force=True)\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_log_decay\n",
    "        self.alpha = alpha\n",
    "        self.alpha_decay = alpha_decay\n",
    "        self.n_episodes = n_episodes\n",
    "        self.n_win_ticks = n_win_ticks\n",
    "        self.batch_size = batch_size\n",
    "        self.quiet = quiet\n",
    "        if max_env_steps is not None: \n",
    "            self.env._max_episode_steps = max_env_steps\n",
    "            \n",
    "        # Init model\n",
    "        self.dqn = DQN()\n",
    "        self.criterion = torch.nn.MSELoss()\n",
    "        self.opt = torch.optim.Adam(self.dqn.parameters(), lr=0.01)\n",
    "        \n",
    "    def get_epsilon(self, t):\n",
    "        #returns some epsilon value based on t that gives a bound on when the agent should act randomly\n",
    "        return max(self.epsilon_min, min(self.epsilon, 1.0 - math.log10((t + 1) * self.epsilon_decay)))\n",
    "    \n",
    "    def preprocess_state(self, state):\n",
    "        #puts the state into a tensor to allow for transforms\n",
    "        return torch.tensor(np.reshape(state, [1, 4]), dtype=torch.float32) \n",
    "    \n",
    "    def choose_action(self, state, epsilon):\n",
    "        #if random drawn number is less than epsilon, act randomly\n",
    "        #else, choose greedy from dqn output\n",
    "        if (np.random.random() <= epsilon):\n",
    "            return self.env.action_space.sample() \n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                return torch.argmax(self.dqn(state)).numpy()\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        #add past actions to deque memory\n",
    "        reward = torch.tensor(reward)\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def replay(self, batch_size):\n",
    "        #take a random minibatch from memory - largeset minibatch size is given by batch_size\n",
    "        #for each minibatch, y is the dqn action from state\n",
    "        \n",
    "        #reward is +1 for surviving another tick, +0 for not living\n",
    "        y_batch, y_target_batch = [], []\n",
    "        minibatch = random.sample(self.memory, min(len(self.memory), batch_size))\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            y = self.dqn(state)\n",
    "            y_target = y.clone().detach()\n",
    "            with torch.no_grad():\n",
    "                y_target[0][action] = reward if done else reward + self.gamma * torch.max(self.dqn(next_state)[0])\n",
    "            y_batch.append(y[0])\n",
    "            y_target_batch.append(y_target[0])\n",
    "        \n",
    "        y_batch = torch.cat(y_batch)\n",
    "        y_target_batch = torch.cat(y_target_batch)\n",
    "        \n",
    "        self.opt.zero_grad()\n",
    "        loss = self.criterion(y_batch, y_target_batch)\n",
    "        loss.backward()\n",
    "        self.opt.step()        \n",
    "        \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "            \n",
    "    def run(self):\n",
    "        scores = deque(maxlen=100)\n",
    "        \n",
    "        for e in range(self.n_episodes):\n",
    "            state = self.preprocess_state(self.env.reset())\n",
    "            done = False\n",
    "            i = 0\n",
    "            while not done:\n",
    "                if e % 100 == 0 and not self.quiet:\n",
    "                    self.env.render()\n",
    "                action = self.choose_action(state, self.get_epsilon(e))\n",
    "                next_state, reward, done, _ = self.env.step(action)\n",
    "                next_state = self.preprocess_state(next_state)\n",
    "                self.remember(state, action, reward, next_state, done)\n",
    "                state = next_state\n",
    "                i += 1\n",
    "            \n",
    "            scores.append(i)\n",
    "            mean_score = np.mean(scores)\n",
    "            if mean_score >= self.n_win_ticks and e >= 100:\n",
    "                if not self.quiet: print('Ran {} episodes. Solved after {} trials ✔'.format(e, e - 100))\n",
    "                return e - 100\n",
    "            if e % 100 == 0 and not self.quiet:\n",
    "                print('[Episode {}] - Mean survival time over last 100 episodes was {} ticks.'.format(e, mean_score))\n",
    "            self.replay(self.batch_size)\n",
    "        \n",
    "        if not self.quiet: print('Did not solve after {} episodes'.format(e))\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a3d00de-9701-48e5-a117-1b5fc8ca6e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode 0] - Mean survival time over last 100 episodes was 59.0 ticks.\n",
      "[Episode 100] - Mean survival time over last 100 episodes was 15.17 ticks.\n",
      "[Episode 200] - Mean survival time over last 100 episodes was 30.61 ticks.\n",
      "[Episode 300] - Mean survival time over last 100 episodes was 64.38 ticks.\n",
      "[Episode 400] - Mean survival time over last 100 episodes was 64.32 ticks.\n",
      "[Episode 500] - Mean survival time over last 100 episodes was 104.4 ticks.\n",
      "[Episode 600] - Mean survival time over last 100 episodes was 138.47 ticks.\n",
      "[Episode 700] - Mean survival time over last 100 episodes was 131.25 ticks.\n",
      "[Episode 800] - Mean survival time over last 100 episodes was 123.09 ticks.\n",
      "[Episode 900] - Mean survival time over last 100 episodes was 194.56 ticks.\n",
      "Ran 908 episodes. Solved after 808 trials ✔\n"
     ]
    }
   ],
   "source": [
    "agent = DQNCartPoleSolver()\n",
    "agent.run()\n",
    "agent.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b50c0231-acc4-4845-a7fa-529ac419c0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0.4204885 ,  0.9172531 ,  0.00251121, -0.93296623], dtype=float32), 1.0, True, {'TimeLimit.truncated': True}) 200\n"
     ]
    }
   ],
   "source": [
    "e = 1000\n",
    "state = agent.preprocess_state(agent.env.reset())\n",
    "done = False\n",
    "i = 0\n",
    "while not done:\n",
    "    with torch.no_grad():\n",
    "        agent.env.render()\n",
    "        action = agent.choose_action(state, agent.get_epsilon(e))\n",
    "        next_state, reward, done, _ = agent.env.step(action)\n",
    "        next_state = agent.preprocess_state(next_state)\n",
    "        #self.remember(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        i += 1\n",
    "print(agent.env.step(action), i)\n",
    "agent.env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
